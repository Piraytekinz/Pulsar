{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a39c69d8-f7aa-4737-b627-c22284a5dbc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\anang\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, add, Conv1D, Conv2D, Dense, Flatten, Dropout, MaxPooling2D, Conv1DTranspose, Reshape, ReLU, MaxPooling1D\n",
    "import os\n",
    "import shutil\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6a6ea38-2fc9-4c5d-817e-aaec3d2c5f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_folders = os.listdir('sound images')\n",
    "sound_folders = os.listdir('audio')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88446868-5919-43c7-adf8-9b4f3ae5058b",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_names = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "444cfcc1-b27d-43d6-8d6c-1bc7e7456c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_audio(audio):\n",
    "    final = []\n",
    "    segment_length=16384\n",
    "    for aud in audio:\n",
    "        # if aud == 'gun':\n",
    "        folder = 'C:/Users/anang/OneDrive/Desktop/Image to Audio/audio/'+aud\n",
    "        num = 0\n",
    "        for file in os.listdir(os.path.join(folder)):\n",
    "            file_name = os.path.join(folder, file)\n",
    "            print(file_name)\n",
    "            audio, _ = librosa.load(file_name, sr=16000)\n",
    "            \n",
    "            num += 1\n",
    "           \n",
    "            print(audio - np.min(audio))\n",
    "            audio = (audio - np.min(audio)) / (np.max(audio) - np.min(audio)) * 2 - 1\n",
    "    \n",
    "            if len(audio) < 150912:\n",
    "                padding = 150912 - len(audio)\n",
    "                audio = np.pad(audio, (0, padding), 'constant')\n",
    "            else:\n",
    "                audio = audio[:150912]\n",
    "\n",
    "            if len(audio) != 150912:\n",
    "                print(f\"Error: Audio length after processing is {len(audio)}, expected {150912}\")\n",
    "            # segments = [audio_padded[i:i+segment_length] for i in range(0, len(audio_padded), segment_length) if len(audio_padded[i:i+segment_length]) == segment_length]\n",
    "    \n",
    "            final.append(audio)\n",
    "            audio_names.append(file_name)\n",
    "\n",
    "            if num == 2:\n",
    "                break\n",
    "            \n",
    "        \n",
    "    return np.array(final)\n",
    "\n",
    "def preprocess_audio(audio, segment_length=16384):\n",
    "    audio = (audio - np.min(audio)) / (np.max(audio) - np.min(audio)) * 2 - 1\n",
    "    # Segment audio\n",
    "    # segments = [audio[i:i+segment_length] for i in range(0, len(audio), segment_length) if len(audio[i:i+segment_length]) == segment_length]\n",
    "    return np.array(audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "84104803-b506-41b7-9990-a5cccd83a7d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/anang/OneDrive/Desktop/Image to Audio/audio/baby\\babycry-6473.1.157.mp3\n",
      "[0.1695587  0.1695587  0.1695587  ... 0.16955869 0.16955851 0.16955936]\n",
      "C:/Users/anang/OneDrive/Desktop/Image to Audio/audio/baby\\babycry-6473.1.mp3\n",
      "[0.1695587  0.1695587  0.1695587  ... 0.16955869 0.16955851 0.16955936]\n",
      "C:/Users/anang/OneDrive/Desktop/Image to Audio/audio/cars\\audi-v8-acceleration-sound-6067.156.mp3\n",
      "[0.89905864 0.89905864 0.89905864 ... 0.89905864 0.89905864 0.89905864]\n",
      "C:/Users/anang/OneDrive/Desktop/Image to Audio/audio/cars\\audi-v8-acceleration-sound-6067.157.mp3\n",
      "[0.89905864 0.89905864 0.89905864 ... 0.89905864 0.89905864 0.89905864]\n",
      "C:/Users/anang/OneDrive/Desktop/Image to Audio/audio/fly\\fly-129618.1.102.mp3\n",
      "[0.7947285 0.7947285 0.7947285 ... 0.7947285 0.7947285 0.7947285]\n",
      "C:/Users/anang/OneDrive/Desktop/Image to Audio/audio/fly\\fly-129618.1.mp3\n",
      "[0.7947285 0.7947285 0.7947285 ... 0.7947285 0.7947285 0.7947285]\n",
      "C:/Users/anang/OneDrive/Desktop/Image to Audio/audio/gun\\9mm-pistol-shot-6349.100.96.mp3\n",
      "[1.2318366 1.2318366 1.2318366 ... 1.2318367 1.2318363 1.2318366]\n",
      "C:/Users/anang/OneDrive/Desktop/Image to Audio/audio/gun\\9mm-pistol-shot-6349.100.mp3\n",
      "[1.2318366 1.2318366 1.2318366 ... 1.2318367 1.2318363 1.2318366]\n",
      "C:/Users/anang/OneDrive/Desktop/Image to Audio/audio/lightning\\thunder-124463.0.120.mp3\n",
      "[0.4983934  0.4983934  0.4983934  ... 0.49839285 0.49839318 0.4983934 ]\n",
      "C:/Users/anang/OneDrive/Desktop/Image to Audio/audio/lightning\\thunder-124463.0.mp3\n",
      "[0.4983934  0.4983934  0.4983934  ... 0.49839285 0.49839318 0.4983934 ]\n",
      "C:/Users/anang/OneDrive/Desktop/Image to Audio/audio/phone\\digital-phone-ring-88932.79.144.0.78.mp3\n",
      "[0.717551 0.717551 0.717551 ... 0.717551 0.717551 0.717551]\n",
      "C:/Users/anang/OneDrive/Desktop/Image to Audio/audio/phone\\digital-phone-ring-88932.79.144.0.mp3\n",
      "[0.717551 0.717551 0.717551 ... 0.717551 0.717551 0.717551]\n",
      "C:/Users/anang/OneDrive/Desktop/Image to Audio/audio/piano\\dramatic-piano-10950.0.137.mp3\n",
      "[0.26347977 0.26347977 0.26347977 ... 0.2634848  0.26347524 0.2634816 ]\n",
      "C:/Users/anang/OneDrive/Desktop/Image to Audio/audio/piano\\dramatic-piano-10950.10.138.mp3\n",
      "[0.26347977 0.26347977 0.26347977 ... 0.2634848  0.26347524 0.2634816 ]\n",
      "C:/Users/anang/OneDrive/Desktop/Image to Audio/audio/Tiger\\monster-warrior-roar-195877.1.92.mp3\n",
      "[0.53152364 0.53152364 0.53152364 ... 0.531524   0.5315234  0.53152406]\n",
      "C:/Users/anang/OneDrive/Desktop/Image to Audio/audio/Tiger\\monster-warrior-roar-195877.1.mp3\n",
      "[0.53152364 0.53152364 0.53152364 ... 0.531524   0.5315234  0.53152406]\n"
     ]
    }
   ],
   "source": [
    "audio = os.listdir(os.path.join('C:/Users/anang/OneDrive/Desktop/Image to Audio/audio/'))\n",
    "audio_segments = load_audio(audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4fbc874f-0798-4a4f-b74b-0fbc9d4d8897",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n"
     ]
    }
   ],
   "source": [
    "print(len(audio_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0ac80903-a975-46c6-a33d-7e3caba864c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_preprocess_image(image_file):\n",
    "    # Load the image from the file path\n",
    "    final = []\n",
    "\n",
    "    for img in image_file:\n",
    "        # if img == 'gun':\n",
    "        folder = 'C:/Users/anang/OneDrive/Desktop/Image to Audio/sound images/'+img\n",
    "        num = 0\n",
    "        for file_name in os.listdir(os.path.join(folder)):\n",
    "            print(file_name)\n",
    "\n",
    "            num += 1\n",
    "            \n",
    "            \n",
    "            file = os.path.join(folder, file_name)\n",
    "            # print(file)\n",
    "            image = tf.io.read_file(file)\n",
    "            # Decode the image (e.g., JPEG or PNG)\n",
    "            image = tf.image.decode_jpeg(image, channels=3)\n",
    "            # Resize the image to your desired dimensions\n",
    "            image = tf.image.resize(image, [128, 128])\n",
    "            # Normalize pixel values (optional)\n",
    "            image = (image / 127.5) - 1\n",
    "            \n",
    "            final.append(image)\n",
    "\n",
    "            if num == 2:\n",
    "                break\n",
    "\n",
    "            \n",
    "    return np.array(final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1ea71211-9dea-4735-b2e1-9dd0bc5d0439",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2457004-crying2.jpg\n",
      "baby-1151351_1280.jpg\n",
      "christian-bowen-856.jpeg\n",
      "download (15).jpg\n",
      "download (15).jpg\n",
      "download (16).jpg\n",
      "1Glock_17_b.jpg\n",
      "2download (15).jpg\n",
      "dark-1836972_1280.jpg\n",
      "download (15).jpg\n",
      "02ca3f80-34d4-414d-81d2-ef3064d1d369.jpg\n",
      "07ebed3b64b7b965190d4025ffbd7f78.jpg\n",
      "ai-generated-8111543_1280.png\n",
      "amigos-2025167_1280.png\n",
      "1animal-4004844_640.jpg\n",
      "amur-tiger-4155922_640.jpg\n"
     ]
    }
   ],
   "source": [
    "images = os.listdir(os.path.join('C:/Users/anang/OneDrive/Desktop/Image to Audio/sound images/'))\n",
    "images = load_and_preprocess_image(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "720d637f-3426-456d-9501-9a670c7b208d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 128, 128, 3)\n",
      "(16, 150912)\n"
     ]
    }
   ],
   "source": [
    "print(images.shape)\n",
    "print(audio_segments.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a66e7aea-a979-4978-8b0c-c8011c85f993",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = tf.data.Dataset.from_tensor_slices((images, audio_segments))\n",
    "data = data.batch(16).shuffle(2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a6f390-da88-458b-b149-b3fbb6b03173",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MEAN SQUARED ERROR LOSS WAS USED IN PLACE O THIS\n",
    "\n",
    "LAMBDA = 100\n",
    "\n",
    "loss_object = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "\n",
    "def generator_loss(disc_generated_output, gen_output, target):\n",
    "  gan_loss = loss_object(tf.ones_like(disc_generated_output), disc_generated_output)\n",
    "\n",
    "  l1_loss = tf.reduce_mean(tf.abs(target - gen_output))\n",
    "\n",
    "  total_gen_loss = gan_loss + (LAMBDA * l1_loss)\n",
    "\n",
    "  return total_gen_loss, gan_loss, l1_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71769613-3c33-4eb7-98e8-4c162af195be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DISCRIMINATOR IS UNUSED IN THIS TEMPLATE\n",
    "def discriminator_loss(disc_real_output, disc_generated_output):\n",
    "  real_loss = loss_object(tf.ones_like(disc_real_output), disc_real_output)\n",
    "\n",
    "  generated_loss = loss_object(tf.zeros_like(disc_generated_output), disc_generated_output)\n",
    "\n",
    "  total_loss = real_loss + generated_loss\n",
    "\n",
    "  return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f70930-e9a6-4fe7-9c67-810da5edf633",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\anang\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\anang\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\pooling\\max_pooling2d.py:161: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 128, 128, 16)      208       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 64, 64, 16)        0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 64, 64, 8)         520       \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 32, 32, 8)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 32, 32, 4)         132       \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPoolin  (None, 16, 16, 4)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 1024)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 75456)             77342400  \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 9432, 8)           0         \n",
      "                                                                 \n",
      " conv1d_transpose (Conv1DTr  (None, 37728, 16)         3216      \n",
      " anspose)                                                        \n",
      "                                                                 \n",
      " conv1d_transpose_1 (Conv1D  (None, 150912, 1)         401       \n",
      " Transpose)                                                      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 77346877 (295.05 MB)\n",
      "Trainable params: 77346877 (295.05 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#CODE FOR BUILDING THE GENERATOR\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "def build_generator(latent_dim, output_shape):\n",
    "    initializer = tf.random_normal_initializer(0., 0.02)\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Input(shape=(128, 128, 3)))\n",
    "    model.add(layers.Conv2D(16, (2,2), strides=1, padding='same', activation='relu'))\n",
    "    model.add(layers.MaxPooling2D())\n",
    "    model.add(layers.Conv2D(8, (2,2), strides=1, padding='same', activation='relu'))\n",
    "    model.add(layers.MaxPooling2D())\n",
    "    model.add(layers.Conv2D(4, (2,2), strides=1, padding='same', activation='relu'))\n",
    "    model.add(layers.MaxPooling2D())\n",
    "    model.add(layers.Flatten())\n",
    "\n",
    "    model.add(Dense(8*(output_shape[0] // 32))),\n",
    "    model.add(Reshape((output_shape[0]//32, 8))),\n",
    "    model.add(Conv1DTranspose(16, kernel_size=25, strides=4, padding='same', activation='relu')),\n",
    "    model.add(Conv1DTranspose(1, kernel_size=25, strides=4, padding='same', activation='tanh')),\n",
    "    \n",
    "        \n",
    "    return model\n",
    "\n",
    "latent_dim = 100\n",
    "output_shape = (301824, 1)\n",
    "\n",
    "generator = build_generator(latent_dim, output_shape)\n",
    "generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c969312-f063-45a1-a1f1-ac072fc6ebc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\anang\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#COMPILING THE GENERATOR\n",
    "\n",
    "generator.compile(optimizer='adam', loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae5342d2-2986-461a-a81f-0526049110f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_3 (Conv2D)           (None, 128, 128, 16)      10816     \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPoolin  (None, 64, 64, 16)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 64, 64, 8)         28808     \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPoolin  (None, 32, 32, 8)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 8192)              0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 4716)              38638188  \n",
      "                                                                 \n",
      " re_lu (ReLU)                (None, 4716)              0         \n",
      "                                                                 \n",
      " reshape_1 (Reshape)         (None, 4716, 1)           0         \n",
      "                                                                 \n",
      " conv1d_transpose_2 (Conv1D  (None, 9432, 128)         3328      \n",
      " Transpose)                                                      \n",
      "                                                                 \n",
      " re_lu_1 (ReLU)              (None, 9432, 128)         0         \n",
      "                                                                 \n",
      " conv1d_transpose_3 (Conv1D  (None, 18864, 64)         204864    \n",
      " Transpose)                                                      \n",
      "                                                                 \n",
      " re_lu_2 (ReLU)              (None, 18864, 64)         0         \n",
      "                                                                 \n",
      " conv1d_transpose_4 (Conv1D  (None, 37728, 32)         51232     \n",
      " Transpose)                                                      \n",
      "                                                                 \n",
      " re_lu_3 (ReLU)              (None, 37728, 32)         0         \n",
      "                                                                 \n",
      " conv1d_transpose_5 (Conv1D  (None, 75456, 16)         12816     \n",
      " Transpose)                                                      \n",
      "                                                                 \n",
      " re_lu_4 (ReLU)              (None, 75456, 16)         0         \n",
      "                                                                 \n",
      " conv1d_transpose_6 (Conv1D  (None, 150912, 8)         3208      \n",
      " Transpose)                                                      \n",
      "                                                                 \n",
      " re_lu_5 (ReLU)              (None, 150912, 8)         0         \n",
      "                                                                 \n",
      " conv1d_transpose_7 (Conv1D  (None, 301824, 1)         201       \n",
      " Transpose)                                                      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 38953461 (148.60 MB)\n",
      "Trainable params: 38953461 (148.60 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#DISCRIMINATOR IS NOT USED IN THIS TEMPLATE\n",
    "\n",
    "def build_discriminator():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Input(shape=(128, 128, 3)))\n",
    "    model.add(layers.Conv2D(16, kernel_size=15, strides=1, padding='same'))\n",
    "    model.add(layers.MaxPooling2D())\n",
    "    model.add(layers.Conv2D(8, kernel_size=15, strides=1, padding='same'))\n",
    "    model.add(layers.MaxPooling2D())\n",
    "    model.add(layers.Flatten())\n",
    "\n",
    "    initial_shape = (output_shape[0] // 128, 2) \n",
    "    model.add(layers.Dense(initial_shape[0] * initial_shape[1]))\n",
    "    model.add(layers.ReLU())\n",
    "\n",
    "    model.add(layers.Reshape((initial_shape[0] * initial_shape[1], 1)))\n",
    "\n",
    "    model.add(layers.Conv1DTranspose(128, kernel_size=25, strides=2, padding='same'))\n",
    "    model.add(layers.ReLU())\n",
    "    model.add(layers.Conv1DTranspose(64, kernel_size=25, strides=2, padding='same'))\n",
    "    model.add(layers.ReLU())\n",
    "    model.add(layers.Conv1DTranspose(32, kernel_size=25, strides=2, padding='same'))\n",
    "    model.add(layers.ReLU())\n",
    "    model.add(layers.Conv1DTranspose(16, kernel_size=25, strides=2, padding='same'))\n",
    "    model.add(layers.ReLU())\n",
    "    model.add(layers.Conv1DTranspose(8, kernel_size=25, strides=2, padding='same'))\n",
    "    model.add(layers.ReLU())\n",
    "\n",
    "    model.add(layers.Conv1DTranspose(1, kernel_size=25, strides=2, padding='same', activation='tanh'))\n",
    "    \n",
    "  \n",
    "    return model\n",
    "\n",
    "discriminator = build_discriminator()\n",
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aee9ca3-75fd-4568-afab-3b95b283efef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\anang\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "0 [G loss: 0.030673667788505554]\n",
      "1 [G loss: 0.03056582808494568]\n",
      "2 [G loss: 0.030465854331851006]\n",
      "3 [G loss: 0.030372129753232002]\n",
      "4 [G loss: 0.030268564820289612]\n",
      "5 [G loss: 0.030142005532979965]\n",
      "6 [G loss: 0.029984595254063606]\n",
      "7 [G loss: 0.02979162335395813]\n",
      "8 [G loss: 0.029561176896095276]\n",
      "9 [G loss: 0.029295777902007103]\n",
      "10 [G loss: 0.029005132615566254]\n",
      "11 [G loss: 0.028704531490802765]\n",
      "12 [G loss: 0.02841140143573284]\n",
      "13 [G loss: 0.028130004182457924]\n",
      "14 [G loss: 0.027835682034492493]\n",
      "15 [G loss: 0.02748962864279747]\n",
      "16 [G loss: 0.027076777070760727]\n",
      "17 [G loss: 0.026614045724272728]\n",
      "18 [G loss: 0.026121824979782104]\n",
      "19 [G loss: 0.025595705956220627]\n",
      "20 [G loss: 0.025004304945468903]\n",
      "21 [G loss: 0.024312637746334076]\n",
      "22 [G loss: 0.023505399003624916]\n",
      "23 [G loss: 0.022600777447223663]\n",
      "24 [G loss: 0.02162960171699524]\n",
      "25 [G loss: 0.020606063306331635]\n",
      "26 [G loss: 0.019558824598789215]\n",
      "27 [G loss: 0.018558958545327187]\n",
      "28 [G loss: 0.017649341374635696]\n",
      "29 [G loss: 0.016804058104753494]\n",
      "30 [G loss: 0.015960589051246643]\n",
      "31 [G loss: 0.015019376762211323]\n",
      "32 [G loss: 0.014002230949699879]\n",
      "33 [G loss: 0.012987732887268066]\n",
      "34 [G loss: 0.012088002637028694]\n",
      "35 [G loss: 0.011297201737761497]\n",
      "36 [G loss: 0.010617089457809925]\n",
      "37 [G loss: 0.009990050457417965]\n",
      "38 [G loss: 0.009402655065059662]\n",
      "39 [G loss: 0.008898511528968811]\n",
      "40 [G loss: 0.008475379087030888]\n",
      "41 [G loss: 0.008103976026177406]\n",
      "42 [G loss: 0.007740038447082043]\n",
      "43 [G loss: 0.007372943218797445]\n",
      "44 [G loss: 0.007031887769699097]\n",
      "45 [G loss: 0.006737145595252514]\n",
      "46 [G loss: 0.006482966244220734]\n",
      "47 [G loss: 0.006247697398066521]\n",
      "48 [G loss: 0.006016561761498451]\n",
      "49 [G loss: 0.005792363081127405]\n",
      "50 [G loss: 0.005585768260061741]\n",
      "51 [G loss: 0.005400211550295353]\n",
      "52 [G loss: 0.005232266150414944]\n",
      "53 [G loss: 0.005072244442999363]\n",
      "54 [G loss: 0.004917128011584282]\n",
      "55 [G loss: 0.004771832376718521]\n",
      "56 [G loss: 0.0046404097229242325]\n",
      "57 [G loss: 0.004522763192653656]\n",
      "58 [G loss: 0.0044151004403829575]\n",
      "59 [G loss: 0.004314272664487362]\n",
      "60 [G loss: 0.004220245871692896]\n",
      "61 [G loss: 0.004133209586143494]\n",
      "62 [G loss: 0.004052431788295507]\n",
      "63 [G loss: 0.003975841216742992]\n",
      "64 [G loss: 0.003902137279510498]\n",
      "65 [G loss: 0.003831788431853056]\n",
      "66 [G loss: 0.0037656882777810097]\n",
      "67 [G loss: 0.003704266855493188]\n",
      "68 [G loss: 0.0036467290483415127]\n",
      "69 [G loss: 0.0035920054651796818]\n",
      "70 [G loss: 0.0035399324260652065]\n",
      "71 [G loss: 0.0034906247165054083]\n",
      "72 [G loss: 0.0034442166797816753]\n",
      "73 [G loss: 0.003400166518986225]\n",
      "74 [G loss: 0.0033580134622752666]\n",
      "75 [G loss: 0.0033176541328430176]\n",
      "76 [G loss: 0.003279412630945444]\n",
      "77 [G loss: 0.0032431655563414097]\n",
      "78 [G loss: 0.0032085422426462173]\n",
      "79 [G loss: 0.0031752977520227432]\n",
      "80 [G loss: 0.0031434274278581142]\n",
      "81 [G loss: 0.003112924052402377]\n",
      "82 [G loss: 0.00308356829918921]\n",
      "83 [G loss: 0.0030552286189049482]\n",
      "84 [G loss: 0.0030278905760496855]\n",
      "85 [G loss: 0.0030014109797775745]\n",
      "86 [G loss: 0.0029758005402982235]\n",
      "87 [G loss: 0.0029509759042412043]\n",
      "88 [G loss: 0.0029269177466630936]\n",
      "89 [G loss: 0.0029035997577011585]\n",
      "90 [G loss: 0.002880900166928768]\n",
      "91 [G loss: 0.0028588285204023123]\n",
      "92 [G loss: 0.0028373058885335922]\n",
      "93 [G loss: 0.002816299442201853]\n",
      "94 [G loss: 0.0027958075515925884]\n",
      "95 [G loss: 0.0027757936622947454]\n",
      "96 [G loss: 0.0027562067843973637]\n",
      "97 [G loss: 0.002737053669989109]\n",
      "98 [G loss: 0.0027183115016669035]\n",
      "99 [G loss: 0.002699953503906727]\n",
      "100 [G loss: 0.0026819382328540087]\n",
      "101 [G loss: 0.0026642256416380405]\n",
      "102 [G loss: 0.0026468331925570965]\n",
      "103 [G loss: 0.002629759255796671]\n",
      "104 [G loss: 0.00261296215467155]\n",
      "105 [G loss: 0.0025964383967220783]\n",
      "106 [G loss: 0.0025801812298595905]\n",
      "107 [G loss: 0.0025641685351729393]\n",
      "108 [G loss: 0.002548396121710539]\n",
      "109 [G loss: 0.002532839309424162]\n",
      "110 [G loss: 0.00251749437302351]\n",
      "111 [G loss: 0.00250234710983932]\n",
      "112 [G loss: 0.0024873786605894566]\n",
      "113 [G loss: 0.0024725887924432755]\n",
      "114 [G loss: 0.0024579758755862713]\n",
      "115 [G loss: 0.0024435194209218025]\n",
      "116 [G loss: 0.0024292422458529472]\n",
      "117 [G loss: 0.002415140625089407]\n",
      "118 [G loss: 0.0024011991918087006]\n",
      "119 [G loss: 0.002387393033131957]\n",
      "120 [G loss: 0.002373749390244484]\n",
      "121 [G loss: 0.002360251732170582]\n",
      "122 [G loss: 0.0023468974977731705]\n",
      "123 [G loss: 0.0023336661979556084]\n",
      "124 [G loss: 0.002320569008588791]\n",
      "125 [G loss: 0.002307609189301729]\n",
      "126 [G loss: 0.0022947858087718487]\n",
      "127 [G loss: 0.002282080939039588]\n",
      "128 [G loss: 0.0022694957442581654]\n",
      "129 [G loss: 0.0022570258006453514]\n",
      "130 [G loss: 0.002244682516902685]\n",
      "131 [G loss: 0.0022324505262076855]\n",
      "132 [G loss: 0.002220326568931341]\n",
      "133 [G loss: 0.0022083385847508907]\n",
      "134 [G loss: 0.0021964581683278084]\n",
      "135 [G loss: 0.002184683922678232]\n",
      "136 [G loss: 0.002173028886318207]\n",
      "137 [G loss: 0.002161493059247732]\n",
      "138 [G loss: 0.002150073414668441]\n",
      "139 [G loss: 0.0021387524902820587]\n",
      "140 [G loss: 0.0021275291219353676]\n",
      "141 [G loss: 0.00211640028283]\n",
      "142 [G loss: 0.00210538599640131]\n",
      "143 [G loss: 0.002094465307891369]\n",
      "144 [G loss: 0.002083650790154934]\n",
      "145 [G loss: 0.002072948031127453]\n",
      "146 [G loss: 0.002062343992292881]\n",
      "147 [G loss: 0.002051857765763998]\n",
      "148 [G loss: 0.0020415023900568485]\n",
      "149 [G loss: 0.002031308598816395]\n",
      "150 [G loss: 0.002021277090534568]\n",
      "151 [G loss: 0.0020115640945732594]\n",
      "152 [G loss: 0.0020021197851747274]\n",
      "153 [G loss: 0.001993537647649646]\n",
      "154 [G loss: 0.001985814655199647]\n",
      "155 [G loss: 0.0019790041260421276]\n",
      "156 [G loss: 0.00197096006013453]\n",
      "157 [G loss: 0.0019618843216449022]\n",
      "158 [G loss: 0.0019523040391504765]\n",
      "159 [G loss: 0.0019447339000180364]\n",
      "160 [G loss: 0.0019415742717683315]\n",
      "161 [G loss: 0.001939615118317306]\n",
      "162 [G loss: 0.001933027640916407]\n",
      "163 [G loss: 0.0019294233061373234]\n",
      "164 [G loss: 0.0019272614736109972]\n",
      "165 [G loss: 0.0019274306250736117]\n",
      "166 [G loss: 0.0019162939861416817]\n",
      "167 [G loss: 0.0019023057539016008]\n",
      "168 [G loss: 0.0018810986075550318]\n",
      "169 [G loss: 0.001861777389422059]\n",
      "170 [G loss: 0.0018500739242881536]\n",
      "171 [G loss: 0.0018470112700015306]\n",
      "172 [G loss: 0.0018435302190482616]\n",
      "173 [G loss: 0.0018367439042776823]\n",
      "174 [G loss: 0.0018298258073627949]\n",
      "175 [G loss: 0.001818015705794096]\n",
      "176 [G loss: 0.001804970670491457]\n",
      "177 [G loss: 0.0017936876974999905]\n",
      "178 [G loss: 0.0017850599251687527]\n",
      "179 [G loss: 0.001776716555468738]\n",
      "180 [G loss: 0.0017679925076663494]\n",
      "181 [G loss: 0.0017620774451643229]\n",
      "182 [G loss: 0.0017582557629793882]\n",
      "183 [G loss: 0.0017534953076392412]\n",
      "184 [G loss: 0.0017484464915469289]\n",
      "185 [G loss: 0.0017460999079048634]\n",
      "186 [G loss: 0.0017452233005315065]\n",
      "187 [G loss: 0.0017467520665377378]\n",
      "188 [G loss: 0.0017486508004367352]\n",
      "189 [G loss: 0.0017508366145193577]\n",
      "190 [G loss: 0.001749270362779498]\n",
      "191 [G loss: 0.0017412544693797827]\n",
      "192 [G loss: 0.001725406851619482]\n",
      "193 [G loss: 0.0017032120376825333]\n",
      "194 [G loss: 0.0016807569190859795]\n",
      "195 [G loss: 0.0016658979002386332]\n",
      "196 [G loss: 0.0016605588607490063]\n",
      "197 [G loss: 0.0016616863431409001]\n",
      "198 [G loss: 0.0016644687857478857]\n",
      "199 [G loss: 0.0016653684433549643]\n",
      "200 [G loss: 0.0016636985819786787]\n",
      "201 [G loss: 0.0016582245007157326]\n",
      "202 [G loss: 0.001648569479584694]\n",
      "203 [G loss: 0.0016351392259821296]\n",
      "204 [G loss: 0.0016212132759392262]\n",
      "205 [G loss: 0.001608746824786067]\n",
      "206 [G loss: 0.0015993970446288586]\n",
      "207 [G loss: 0.0015930116642266512]\n",
      "208 [G loss: 0.0015887757763266563]\n",
      "209 [G loss: 0.0015864886809140444]\n",
      "210 [G loss: 0.0015856269747018814]\n",
      "211 [G loss: 0.001586980652064085]\n",
      "212 [G loss: 0.0015915558906272054]\n",
      "213 [G loss: 0.0016005176585167646]\n",
      "214 [G loss: 0.0016153324395418167]\n",
      "215 [G loss: 0.0016327670309692621]\n",
      "216 [G loss: 0.0016486532986164093]\n",
      "217 [G loss: 0.0016450830735266209]\n",
      "218 [G loss: 0.001617153757251799]\n",
      "219 [G loss: 0.0015696879709139466]\n",
      "220 [G loss: 0.0015360903926193714]\n",
      "221 [G loss: 0.0015340462559834123]\n",
      "222 [G loss: 0.0015510939992964268]\n",
      "223 [G loss: 0.0015628430992364883]\n",
      "224 [G loss: 0.0015522106550633907]\n",
      "225 [G loss: 0.0015275514451786876]\n",
      "226 [G loss: 0.0015054505784064531]\n",
      "227 [G loss: 0.0014992787037044764]\n",
      "228 [G loss: 0.0015052224043756723]\n",
      "229 [G loss: 0.0015097795985639095]\n",
      "230 [G loss: 0.0015046007465571165]\n",
      "231 [G loss: 0.0014900820096954703]\n",
      "232 [G loss: 0.0014761348720639944]\n",
      "233 [G loss: 0.0014688640367239714]\n",
      "234 [G loss: 0.0014675520360469818]\n",
      "235 [G loss: 0.0014682207256555557]\n",
      "236 [G loss: 0.0014670637901872396]\n",
      "237 [G loss: 0.0014630042714998126]\n",
      "238 [G loss: 0.0014562334399670362]\n",
      "239 [G loss: 0.001448549097403884]\n",
      "240 [G loss: 0.0014417398488149047]\n",
      "241 [G loss: 0.0014369376003742218]\n",
      "242 [G loss: 0.0014342812355607748]\n",
      "243 [G loss: 0.0014332900755107403]\n",
      "244 [G loss: 0.001433572149835527]\n",
      "245 [G loss: 0.0014345040544867516]\n",
      "246 [G loss: 0.0014356519095599651]\n",
      "247 [G loss: 0.0014358307234942913]\n",
      "248 [G loss: 0.0014370055869221687]\n",
      "249 [G loss: 0.0014380189822986722]\n",
      "250 [G loss: 0.001440616906620562]\n",
      "251 [G loss: 0.001441497472114861]\n",
      "252 [G loss: 0.0014465607237070799]\n",
      "253 [G loss: 0.0014487984590232372]\n",
      "254 [G loss: 0.001449488801881671]\n",
      "255 [G loss: 0.0014446591958403587]\n",
      "256 [G loss: 0.0014373540179803967]\n",
      "257 [G loss: 0.001419866573996842]\n",
      "258 [G loss: 0.001400306704454124]\n",
      "259 [G loss: 0.001385504612699151]\n",
      "260 [G loss: 0.0013786440249532461]\n",
      "261 [G loss: 0.0013763295719400048]\n",
      "262 [G loss: 0.0013742466690018773]\n",
      "263 [G loss: 0.0013731777435168624]\n",
      "264 [G loss: 0.0013717461843043566]\n",
      "265 [G loss: 0.001369803212583065]\n",
      "266 [G loss: 0.0013646972365677357]\n",
      "267 [G loss: 0.0013585464330390096]\n",
      "268 [G loss: 0.0013510799035429955]\n",
      "269 [G loss: 0.0013434413122013211]\n",
      "270 [G loss: 0.0013362145982682705]\n",
      "271 [G loss: 0.0013305300381034613]\n",
      "272 [G loss: 0.0013257975224405527]\n",
      "273 [G loss: 0.001321437070146203]\n",
      "274 [G loss: 0.0013178717344999313]\n",
      "275 [G loss: 0.0013148717116564512]\n",
      "276 [G loss: 0.0013122098753228784]\n",
      "277 [G loss: 0.001310016494244337]\n",
      "278 [G loss: 0.0013092871522530913]\n",
      "279 [G loss: 0.0013103773817420006]\n",
      "280 [G loss: 0.0013154465705156326]\n",
      "281 [G loss: 0.0013261239510029554]\n",
      "282 [G loss: 0.001350250793620944]\n",
      "283 [G loss: 0.00138794572558254]\n",
      "284 [G loss: 0.0014567377511411905]\n",
      "285 [G loss: 0.0015121928881853819]\n",
      "286 [G loss: 0.0015496899140998721]\n",
      "287 [G loss: 0.0014543530996888876]\n",
      "288 [G loss: 0.0013384781777858734]\n",
      "289 [G loss: 0.0013116737827658653]\n",
      "290 [G loss: 0.0013701454736292362]\n",
      "291 [G loss: 0.00139319256413728]\n",
      "292 [G loss: 0.0013193574268370867]\n",
      "293 [G loss: 0.0012841448187828064]\n",
      "294 [G loss: 0.0013221068074926734]\n",
      "295 [G loss: 0.0013272317592054605]\n",
      "296 [G loss: 0.0012847722973674536]\n",
      "297 [G loss: 0.0012677132617682219]\n",
      "298 [G loss: 0.0012907575583085418]\n",
      "299 [G loss: 0.0012886131880804896]\n",
      "300 [G loss: 0.0012565457727760077]\n",
      "301 [G loss: 0.0012549646198749542]\n",
      "302 [G loss: 0.0012688857968896627]\n",
      "303 [G loss: 0.0012555873254314065]\n",
      "304 [G loss: 0.0012384781148284674]\n",
      "305 [G loss: 0.0012416609097272158]\n",
      "306 [G loss: 0.0012452821247279644]\n",
      "307 [G loss: 0.0012346995063126087]\n",
      "308 [G loss: 0.001225069398060441]\n",
      "309 [G loss: 0.001226788037456572]\n",
      "310 [G loss: 0.001227149274200201]\n",
      "311 [G loss: 0.0012192816939204931]\n",
      "312 [G loss: 0.00121274683624506]\n",
      "313 [G loss: 0.0012121610343456268]\n",
      "314 [G loss: 0.001211593858897686]\n",
      "315 [G loss: 0.0012069992953911424]\n",
      "316 [G loss: 0.0012013805098831654]\n",
      "317 [G loss: 0.001198943005874753]\n",
      "318 [G loss: 0.0011981226271018386]\n",
      "319 [G loss: 0.0011957765091210604]\n",
      "320 [G loss: 0.0011920828837901354]\n",
      "321 [G loss: 0.0011889950837939978]\n",
      "322 [G loss: 0.0011876828502863646]\n",
      "323 [G loss: 0.0011876325588673353]\n",
      "324 [G loss: 0.0011880241800099611]\n",
      "325 [G loss: 0.001189210219308734]\n",
      "326 [G loss: 0.0011917594820261002]\n",
      "327 [G loss: 0.0011965255253016949]\n",
      "328 [G loss: 0.0012014746898785233]\n",
      "329 [G loss: 0.001204994972795248]\n",
      "330 [G loss: 0.0012066958006471395]\n",
      "331 [G loss: 0.0012072263052687049]\n",
      "332 [G loss: 0.001206674613058567]\n",
      "333 [G loss: 0.001202595653012395]\n",
      "334 [G loss: 0.0011990200728178024]\n",
      "335 [G loss: 0.0011960826814174652]\n",
      "336 [G loss: 0.0011942117707803845]\n",
      "337 [G loss: 0.0011896619107574224]\n",
      "338 [G loss: 0.0011823105160146952]\n",
      "339 [G loss: 0.001175504643470049]\n",
      "340 [G loss: 0.0011727630626410246]\n",
      "341 [G loss: 0.0011701026232913136]\n",
      "342 [G loss: 0.0011663055047392845]\n",
      "343 [G loss: 0.0011609452776610851]\n",
      "344 [G loss: 0.0011569387279450893]\n",
      "345 [G loss: 0.001153819146566093]\n",
      "346 [G loss: 0.0011519448598846793]\n",
      "347 [G loss: 0.0011494746431708336]\n",
      "348 [G loss: 0.001147609669715166]\n",
      "349 [G loss: 0.0011441681999713182]\n",
      "350 [G loss: 0.0011423288378864527]\n",
      "351 [G loss: 0.0011404502438381314]\n",
      "352 [G loss: 0.0011411469895392656]\n",
      "353 [G loss: 0.0011403127573430538]\n",
      "354 [G loss: 0.0011422648094594479]\n",
      "355 [G loss: 0.0011426309356465936]\n",
      "356 [G loss: 0.0011484131682664156]\n",
      "357 [G loss: 0.0011506401933729649]\n",
      "358 [G loss: 0.0011592174414545298]\n",
      "359 [G loss: 0.0011598974233493209]\n",
      "360 [G loss: 0.0011675652349367738]\n",
      "361 [G loss: 0.0011639781296253204]\n",
      "362 [G loss: 0.0011658377479761839]\n",
      "363 [G loss: 0.0011566750472411513]\n",
      "364 [G loss: 0.001151271048001945]\n",
      "365 [G loss: 0.0011435385094955564]\n",
      "366 [G loss: 0.0011376591864973307]\n",
      "367 [G loss: 0.0011332584545016289]\n",
      "368 [G loss: 0.0011261696927249432]\n",
      "369 [G loss: 0.001121901674196124]\n",
      "370 [G loss: 0.0011146776378154755]\n",
      "371 [G loss: 0.0011100585106760263]\n",
      "372 [G loss: 0.0011051499750465155]\n",
      "373 [G loss: 0.001103652990423143]\n",
      "374 [G loss: 0.0011031096801161766]\n",
      "375 [G loss: 0.0011029838351532817]\n",
      "376 [G loss: 0.0011017018696293235]\n",
      "377 [G loss: 0.0010990414302796125]\n",
      "378 [G loss: 0.001096328254789114]\n",
      "379 [G loss: 0.0010934278834611177]\n",
      "380 [G loss: 0.0010905044618993998]\n",
      "381 [G loss: 0.0010876485612243414]\n",
      "382 [G loss: 0.0010851055849343538]\n",
      "383 [G loss: 0.0010837824083864689]\n",
      "384 [G loss: 0.001082536531612277]\n",
      "385 [G loss: 0.0010827755322679877]\n",
      "386 [G loss: 0.0010826756479218602]\n",
      "387 [G loss: 0.0010854953434318304]\n",
      "388 [G loss: 0.001088251592591405]\n",
      "389 [G loss: 0.0010969298891723156]\n",
      "390 [G loss: 0.0011043907143175602]\n",
      "391 [G loss: 0.0011216944549232721]\n",
      "392 [G loss: 0.0011317976750433445]\n",
      "393 [G loss: 0.0011522809509187937]\n",
      "394 [G loss: 0.0011491798795759678]\n",
      "395 [G loss: 0.0011470115277916193]\n",
      "396 [G loss: 0.0011173004750162363]\n",
      "397 [G loss: 0.0010904959635809064]\n",
      "398 [G loss: 0.001071782549843192]\n",
      "399 [G loss: 0.0010688919574022293]\n",
      "400 [G loss: 0.0010780140291899443]\n",
      "401 [G loss: 0.0010822417680174112]\n",
      "402 [G loss: 0.0010822975309565663]\n",
      "403 [G loss: 0.001069455873221159]\n",
      "404 [G loss: 0.0010576732456684113]\n",
      "405 [G loss: 0.0010499748168513179]\n",
      "406 [G loss: 0.0010489668929949403]\n",
      "407 [G loss: 0.0010521271033212543]\n",
      "408 [G loss: 0.0010526280384510756]\n",
      "409 [G loss: 0.0010513716842979193]\n",
      "410 [G loss: 0.0010454172734171152]\n",
      "411 [G loss: 0.0010399604216217995]\n",
      "412 [G loss: 0.0010351603850722313]\n",
      "413 [G loss: 0.0010329477954655886]\n",
      "414 [G loss: 0.0010324661852791905]\n",
      "415 [G loss: 0.0010322891175746918]\n",
      "416 [G loss: 0.0010319198481738567]\n",
      "417 [G loss: 0.001030354993417859]\n",
      "418 [G loss: 0.0010292669758200645]\n",
      "419 [G loss: 0.0010280186543241143]\n",
      "420 [G loss: 0.0010279049165546894]\n",
      "421 [G loss: 0.0010274520609527826]\n",
      "422 [G loss: 0.0010276618413627148]\n",
      "423 [G loss: 0.0010276228422299027]\n",
      "424 [G loss: 0.001028468948788941]\n",
      "425 [G loss: 0.0010295063257217407]\n",
      "426 [G loss: 0.0010314786341041327]\n",
      "427 [G loss: 0.001033420441672206]\n",
      "428 [G loss: 0.001036316272802651]\n",
      "429 [G loss: 0.0010400861501693726]\n",
      "430 [G loss: 0.001045269425958395]\n",
      "431 [G loss: 0.0010522729717195034]\n",
      "432 [G loss: 0.0010611927136778831]\n",
      "433 [G loss: 0.0010715946555137634]\n",
      "434 [G loss: 0.0010830166283994913]\n",
      "435 [G loss: 0.0010916620958596468]\n",
      "436 [G loss: 0.0010942069347947836]\n",
      "437 [G loss: 0.0010814422275871038]\n",
      "438 [G loss: 0.001058428082615137]\n",
      "439 [G loss: 0.0010342344176024199]\n",
      "440 [G loss: 0.001020216615870595]\n",
      "441 [G loss: 0.0010178603697568178]\n",
      "442 [G loss: 0.0010227053426206112]\n",
      "443 [G loss: 0.0010252417996525764]\n",
      "444 [G loss: 0.0010214966023340821]\n",
      "445 [G loss: 0.0010130037553608418]\n",
      "446 [G loss: 0.0010041167261078954]\n",
      "447 [G loss: 0.0010002299677580595]\n",
      "448 [G loss: 0.000998345552943647]\n",
      "449 [G loss: 0.000998223666101694]\n",
      "450 [G loss: 0.0009963189950212836]\n",
      "451 [G loss: 0.00099375715944916]\n",
      "452 [G loss: 0.000989908934570849]\n",
      "453 [G loss: 0.0009861895814538002]\n",
      "454 [G loss: 0.0009838452097028494]\n",
      "455 [G loss: 0.000982310506515205]\n",
      "456 [G loss: 0.0009815361117944121]\n",
      "457 [G loss: 0.000979812117293477]\n",
      "458 [G loss: 0.0009786332957446575]\n",
      "459 [G loss: 0.0009769510943442583]\n",
      "460 [G loss: 0.0009762663394212723]\n",
      "461 [G loss: 0.0009747933363541961]\n",
      "462 [G loss: 0.0009741576504893601]\n",
      "463 [G loss: 0.0009734255727380514]\n",
      "464 [G loss: 0.0009751925827004015]\n",
      "465 [G loss: 0.0009774286299943924]\n",
      "466 [G loss: 0.0009846653556451201]\n",
      "467 [G loss: 0.0009929484222084284]\n",
      "468 [G loss: 0.0010129939764738083]\n",
      "469 [G loss: 0.001029882114380598]\n",
      "470 [G loss: 0.0010662401327863336]\n",
      "471 [G loss: 0.0010734924580901861]\n",
      "472 [G loss: 0.0010917003965005279]\n",
      "473 [G loss: 0.001052667386829853]\n",
      "474 [G loss: 0.0010158834047615528]\n",
      "475 [G loss: 0.0009807259775698185]\n",
      "476 [G loss: 0.0009752601617947221]\n",
      "477 [G loss: 0.0009924760088324547]\n",
      "478 [G loss: 0.0010001801420003176]\n",
      "479 [G loss: 0.0009971471736207604]\n",
      "480 [G loss: 0.000976173731032759]\n",
      "481 [G loss: 0.0009630368440411985]\n",
      "482 [G loss: 0.0009629972046241164]\n",
      "483 [G loss: 0.0009678209316916764]\n",
      "484 [G loss: 0.0009711632737889886]\n",
      "485 [G loss: 0.00096369837410748]\n",
      "486 [G loss: 0.0009556288132444024]\n",
      "487 [G loss: 0.0009503061301074922]\n",
      "488 [G loss: 0.0009501005988568068]\n",
      "489 [G loss: 0.000952382106333971]\n",
      "490 [G loss: 0.0009512546239420772]\n",
      "491 [G loss: 0.0009486182825639844]\n",
      "492 [G loss: 0.0009436884429305792]\n",
      "493 [G loss: 0.0009407878387719393]\n",
      "494 [G loss: 0.0009394281078130007]\n",
      "495 [G loss: 0.0009388674516230822]\n",
      "496 [G loss: 0.0009385376470163465]\n",
      "497 [G loss: 0.0009370916523039341]\n",
      "498 [G loss: 0.0009360448457300663]\n",
      "499 [G loss: 0.0009343189303763211]\n",
      "500 [G loss: 0.0009332195622846484]\n",
      "501 [G loss: 0.0009316154755651951]\n",
      "502 [G loss: 0.0009305240237154067]\n",
      "503 [G loss: 0.0009293576003983617]\n",
      "504 [G loss: 0.000928645022213459]\n",
      "505 [G loss: 0.0009282133542001247]\n",
      "506 [G loss: 0.0009283669642172754]\n",
      "507 [G loss: 0.000929111847653985]\n",
      "508 [G loss: 0.0009305087151005864]\n",
      "509 [G loss: 0.0009325178107246757]\n",
      "510 [G loss: 0.000935180694796145]\n",
      "511 [G loss: 0.0009377062087878585]\n",
      "512 [G loss: 0.0009402580326423049]\n",
      "513 [G loss: 0.0009420912829227746]\n",
      "514 [G loss: 0.0009443607414141297]\n",
      "515 [G loss: 0.0009474863763898611]\n",
      "516 [G loss: 0.0009510906529612839]\n",
      "517 [G loss: 0.0009555919095873833]\n",
      "518 [G loss: 0.0009603167418390512]\n",
      "519 [G loss: 0.000972671783529222]\n",
      "520 [G loss: 0.0009894717950373888]\n",
      "521 [G loss: 0.0010215264046564698]\n",
      "522 [G loss: 0.0010427035158500075]\n",
      "523 [G loss: 0.0010672828648239374]\n",
      "524 [G loss: 0.0010436051525175571]\n",
      "525 [G loss: 0.0010062037035822868]\n",
      "526 [G loss: 0.0009540074388496578]\n",
      "527 [G loss: 0.0009351151529699564]\n",
      "528 [G loss: 0.0009504693443886936]\n",
      "529 [G loss: 0.0009660526411607862]\n",
      "530 [G loss: 0.0009627788094803691]\n",
      "531 [G loss: 0.0009353296482004225]\n",
      "532 [G loss: 0.0009204907692037523]\n",
      "533 [G loss: 0.0009261862142011523]\n",
      "534 [G loss: 0.0009341470431536436]\n",
      "535 [G loss: 0.0009308933513239026]\n",
      "536 [G loss: 0.0009171151323243976]\n",
      "537 [G loss: 0.0009108798112720251]\n",
      "538 [G loss: 0.0009127655648626387]\n",
      "539 [G loss: 0.000914673088118434]\n",
      "540 [G loss: 0.0009123143972828984]\n",
      "541 [G loss: 0.0009061646414920688]\n",
      "542 [G loss: 0.000902185682207346]\n",
      "543 [G loss: 0.000901208957657218]\n",
      "544 [G loss: 0.0009018815471790731]\n",
      "545 [G loss: 0.0009011032525449991]\n",
      "546 [G loss: 0.0008978989208117127]\n",
      "547 [G loss: 0.0008946912130340934]\n",
      "548 [G loss: 0.0008929118630476296]\n",
      "549 [G loss: 0.0008925392758101225]\n",
      "550 [G loss: 0.0008920274558477104]\n",
      "551 [G loss: 0.0008907860610634089]\n",
      "552 [G loss: 0.0008891359902918339]\n",
      "553 [G loss: 0.0008874458726495504]\n",
      "554 [G loss: 0.0008860665839165449]\n",
      "555 [G loss: 0.000884884677361697]\n",
      "556 [G loss: 0.0008839829242788255]\n",
      "557 [G loss: 0.000883368426002562]\n",
      "558 [G loss: 0.0008826954290270805]\n",
      "559 [G loss: 0.0008819479262456298]\n",
      "560 [G loss: 0.000880954903550446]\n",
      "561 [G loss: 0.0008803628152236342]\n",
      "562 [G loss: 0.0008800338837318122]\n",
      "563 [G loss: 0.0008805956458672881]\n",
      "564 [G loss: 0.0008814617176540196]\n",
      "565 [G loss: 0.0008843289106152952]\n",
      "566 [G loss: 0.0008881287649273872]\n",
      "567 [G loss: 0.0008977783145383]\n",
      "568 [G loss: 0.0009087507496587932]\n",
      "569 [G loss: 0.0009324712445959449]\n",
      "570 [G loss: 0.0009486605413258076]\n",
      "571 [G loss: 0.0009795401711016893]\n",
      "572 [G loss: 0.0009713752078823745]\n",
      "573 [G loss: 0.0009633613517507911]\n",
      "574 [G loss: 0.0009223437518812716]\n",
      "575 [G loss: 0.0008970078779384494]\n",
      "576 [G loss: 0.0008918732637539506]\n",
      "577 [G loss: 0.0009009278146550059]\n",
      "578 [G loss: 0.0009114048443734646]\n",
      "579 [G loss: 0.0009027101332321763]\n",
      "580 [G loss: 0.0008913427009247243]\n",
      "581 [G loss: 0.0008811892475932837]\n",
      "582 [G loss: 0.0008807748672552407]\n",
      "583 [G loss: 0.0008846834534779191]\n",
      "584 [G loss: 0.0008831755840219557]\n",
      "585 [G loss: 0.0008791317814029753]\n",
      "586 [G loss: 0.0008727489039301872]\n",
      "587 [G loss: 0.0008702241466380656]\n",
      "588 [G loss: 0.0008703264757059515]\n",
      "589 [G loss: 0.0008701871265657246]\n",
      "590 [G loss: 0.000869363488163799]\n",
      "591 [G loss: 0.0008665138157084584]\n",
      "592 [G loss: 0.0008642536122351885]\n",
      "593 [G loss: 0.0008622595341876149]\n",
      "594 [G loss: 0.0008609244832769036]\n",
      "595 [G loss: 0.0008599614375270903]\n",
      "596 [G loss: 0.0008588694036006927]\n",
      "597 [G loss: 0.0008583110757172108]\n",
      "598 [G loss: 0.0008573882514610887]\n",
      "599 [G loss: 0.0008566303877159953]\n",
      "600 [G loss: 0.000855334335938096]\n",
      "601 [G loss: 0.0008542151772417128]\n",
      "602 [G loss: 0.000853010977152735]\n",
      "603 [G loss: 0.000852250843308866]\n",
      "604 [G loss: 0.000851654855068773]\n",
      "605 [G loss: 0.0008512302301824093]\n",
      "606 [G loss: 0.000850916316267103]\n",
      "607 [G loss: 0.000850916258059442]\n",
      "608 [G loss: 0.0008511338965035975]\n",
      "609 [G loss: 0.0008516829693689942]\n",
      "610 [G loss: 0.0008525350131094456]\n",
      "611 [G loss: 0.0008539463160559535]\n",
      "612 [G loss: 0.0008561087306588888]\n",
      "613 [G loss: 0.0008602385059930384]\n",
      "614 [G loss: 0.0008662685286253691]\n",
      "615 [G loss: 0.0008784611709415913]\n",
      "616 [G loss: 0.0008947638561949134]\n",
      "617 [G loss: 0.0009307552827522159]\n",
      "618 [G loss: 0.0009661051444709301]\n",
      "619 [G loss: 0.0010385962668806314]\n",
      "620 [G loss: 0.001044820062816143]\n",
      "621 [G loss: 0.0010504121892154217]\n",
      "622 [G loss: 0.0009563009953126311]\n",
      "623 [G loss: 0.0008899755775928497]\n",
      "624 [G loss: 0.0008889044402167201]\n",
      "625 [G loss: 0.0009191361605189741]\n",
      "626 [G loss: 0.000932972994633019]\n",
      "627 [G loss: 0.000889481627382338]\n",
      "628 [G loss: 0.0008641805034130812]\n",
      "629 [G loss: 0.0008786221733316779]\n",
      "630 [G loss: 0.0008880315581336617]\n",
      "631 [G loss: 0.0008764977101236582]\n",
      "632 [G loss: 0.0008551332866773009]\n",
      "633 [G loss: 0.0008564444142393768]\n",
      "634 [G loss: 0.0008677244186401367]\n",
      "635 [G loss: 0.0008599830907769501]\n",
      "636 [G loss: 0.0008478775271214545]\n",
      "637 [G loss: 0.0008453491609543562]\n",
      "638 [G loss: 0.0008496539667248726]\n",
      "639 [G loss: 0.0008494576322846115]\n",
      "640 [G loss: 0.0008414762560278177]\n",
      "641 [G loss: 0.0008378056809306145]\n",
      "642 [G loss: 0.0008392605232074857]\n",
      "643 [G loss: 0.0008393306052312255]\n",
      "644 [G loss: 0.0008365641115233302]\n",
      "645 [G loss: 0.0008325658272951841]\n",
      "646 [G loss: 0.0008314854931086302]\n",
      "647 [G loss: 0.0008319253684021533]\n",
      "648 [G loss: 0.0008309722179546952]\n",
      "649 [G loss: 0.0008289149263873696]\n",
      "650 [G loss: 0.0008267725352197886]\n",
      "651 [G loss: 0.0008258738671429455]\n",
      "652 [G loss: 0.0008255097200162709]\n",
      "653 [G loss: 0.0008247060468420386]\n",
      "654 [G loss: 0.0008235888089984655]\n",
      "655 [G loss: 0.000822237809188664]\n",
      "656 [G loss: 0.0008212231332436204]\n",
      "657 [G loss: 0.0008205013582482934]\n",
      "658 [G loss: 0.0008198914583772421]\n",
      "659 [G loss: 0.0008192997192963958]\n",
      "660 [G loss: 0.0008184914477169514]\n",
      "661 [G loss: 0.0008176519768312573]\n",
      "662 [G loss: 0.0008167460327968001]\n",
      "663 [G loss: 0.0008160486468113959]\n",
      "664 [G loss: 0.0008155411342158914]\n",
      "665 [G loss: 0.0008151703514158726]\n",
      "666 [G loss: 0.0008147798362188041]\n",
      "667 [G loss: 0.0008143248851411045]\n",
      "668 [G loss: 0.0008137935074046254]\n",
      "669 [G loss: 0.0008133853552863002]\n",
      "670 [G loss: 0.0008132528746500611]\n",
      "671 [G loss: 0.0008132983930408955]\n",
      "672 [G loss: 0.0008136595133692026]\n",
      "673 [G loss: 0.0008142351289279759]\n",
      "674 [G loss: 0.0008152591763064265]\n",
      "675 [G loss: 0.0008166844490915537]\n",
      "676 [G loss: 0.0008190768421627581]\n",
      "677 [G loss: 0.0008219412993639708]\n",
      "678 [G loss: 0.0008263493655249476]\n",
      "679 [G loss: 0.000830509583465755]\n",
      "680 [G loss: 0.0008368517155759037]\n",
      "681 [G loss: 0.0008411196758970618]\n",
      "682 [G loss: 0.0008494339417666197]\n",
      "683 [G loss: 0.0008526705205440521]\n",
      "684 [G loss: 0.0008622730965726078]\n",
      "685 [G loss: 0.0008607844356447458]\n",
      "686 [G loss: 0.0008641506428830326]\n",
      "687 [G loss: 0.000852863653562963]\n",
      "688 [G loss: 0.0008458922966383398]\n",
      "689 [G loss: 0.0008331697899848223]\n",
      "690 [G loss: 0.000826558331027627]\n",
      "691 [G loss: 0.0008238372975029051]\n",
      "692 [G loss: 0.0008231338579207659]\n",
      "693 [G loss: 0.0008242589537985623]\n",
      "694 [G loss: 0.0008218140574172139]\n",
      "695 [G loss: 0.0008200936135835946]\n",
      "696 [G loss: 0.0008159368298947811]\n",
      "697 [G loss: 0.0008129840716719627]\n",
      "698 [G loss: 0.0008100727573037148]\n",
      "699 [G loss: 0.0008084482979029417]\n",
      "700 [G loss: 0.0008079219842329621]\n",
      "701 [G loss: 0.0008071060874499381]\n",
      "702 [G loss: 0.0008065124857239425]\n",
      "703 [G loss: 0.0008049766765907407]\n",
      "704 [G loss: 0.0008038230007514358]\n",
      "705 [G loss: 0.0008022687979973853]\n",
      "706 [G loss: 0.0008014147751964629]\n",
      "707 [G loss: 0.0008003190741874278]\n",
      "708 [G loss: 0.000799630070105195]\n",
      "709 [G loss: 0.0007987185381352901]\n",
      "710 [G loss: 0.000798327848315239]\n",
      "711 [G loss: 0.0007978407666087151]\n",
      "712 [G loss: 0.0007978868088684976]\n",
      "713 [G loss: 0.0007980884402059019]\n",
      "714 [G loss: 0.0007994795450940728]\n",
      "715 [G loss: 0.000801451038569212]\n",
      "716 [G loss: 0.0008059116080403328]\n",
      "717 [G loss: 0.0008110516937449574]\n",
      "718 [G loss: 0.0008211369859054685]\n",
      "719 [G loss: 0.0008302574278786778]\n",
      "720 [G loss: 0.0008471710025332868]\n",
      "721 [G loss: 0.000855020247399807]\n",
      "722 [G loss: 0.0008682776242494583]\n",
      "723 [G loss: 0.0008585155592299998]\n",
      "724 [G loss: 0.0008477494702674448]\n",
      "725 [G loss: 0.0008230471285060048]\n",
      "726 [G loss: 0.0008056279039010406]\n",
      "727 [G loss: 0.0007985708070918918]\n",
      "728 [G loss: 0.000801880145445466]\n",
      "729 [G loss: 0.0008107345784083009]\n",
      "730 [G loss: 0.000814324535895139]\n",
      "731 [G loss: 0.0008149652276188135]\n",
      "732 [G loss: 0.0008069465402513742]\n",
      "733 [G loss: 0.0007993025938048959]\n",
      "734 [G loss: 0.0007927902042865753]\n",
      "735 [G loss: 0.0007908461848273873]\n",
      "736 [G loss: 0.000792459468357265]\n",
      "737 [G loss: 0.0007945777615532279]\n",
      "738 [G loss: 0.0007966181728988886]\n",
      "739 [G loss: 0.0007953239255584776]\n",
      "740 [G loss: 0.0007934930035844445]\n",
      "741 [G loss: 0.0007897374453023076]\n",
      "742 [G loss: 0.0007870260160416365]\n",
      "743 [G loss: 0.0007848555105738342]\n",
      "744 [G loss: 0.0007841790793463588]\n",
      "745 [G loss: 0.000784211908467114]\n",
      "746 [G loss: 0.0007846036460250616]\n",
      "747 [G loss: 0.0007852530688978732]\n",
      "748 [G loss: 0.0007855641306377947]\n",
      "749 [G loss: 0.0007859761244617403]\n",
      "750 [G loss: 0.0007858681492507458]\n",
      "751 [G loss: 0.0007860883488319814]\n",
      "752 [G loss: 0.0007860436453483999]\n",
      "753 [G loss: 0.0007863698992878199]\n",
      "754 [G loss: 0.0007864835788495839]\n",
      "755 [G loss: 0.0007869343389756978]\n",
      "756 [G loss: 0.0007876473828218877]\n",
      "757 [G loss: 0.0007887686952017248]\n",
      "758 [G loss: 0.0007909094565548003]\n",
      "759 [G loss: 0.0007929869461804628]\n",
      "760 [G loss: 0.0007964159012772143]\n",
      "761 [G loss: 0.0007990755839273334]\n",
      "762 [G loss: 0.0008045692229643464]\n",
      "763 [G loss: 0.0008084798464551568]\n",
      "764 [G loss: 0.000816797255538404]\n",
      "765 [G loss: 0.0008200309239327908]\n",
      "766 [G loss: 0.0008274185820482671]\n",
      "767 [G loss: 0.0008228464284911752]\n",
      "768 [G loss: 0.0008215381531044841]\n",
      "769 [G loss: 0.0008097979589365423]\n",
      "770 [G loss: 0.0008032912737689912]\n",
      "771 [G loss: 0.000796178006567061]\n",
      "772 [G loss: 0.0007957948837429285]\n",
      "773 [G loss: 0.0007962769595906138]\n",
      "774 [G loss: 0.0007967386627569795]\n",
      "775 [G loss: 0.0007946998812258244]\n",
      "776 [G loss: 0.0007897957693785429]\n",
      "777 [G loss: 0.0007845323998481035]\n",
      "778 [G loss: 0.000780299014877528]\n",
      "779 [G loss: 0.0007777195423841476]\n",
      "780 [G loss: 0.0007768151117488742]\n",
      "781 [G loss: 0.0007761362940073013]\n",
      "782 [G loss: 0.0007760691223666072]\n",
      "783 [G loss: 0.0007750523509457707]\n",
      "784 [G loss: 0.0007739198044873774]\n",
      "785 [G loss: 0.0007720566354691982]\n",
      "786 [G loss: 0.0007705544121563435]\n",
      "787 [G loss: 0.0007695592357777059]\n",
      "788 [G loss: 0.0007689753547310829]\n",
      "789 [G loss: 0.0007688674377277493]\n",
      "790 [G loss: 0.0007684918818995357]\n",
      "791 [G loss: 0.000768932222854346]\n",
      "792 [G loss: 0.0007692364742979407]\n",
      "793 [G loss: 0.0007716447580605745]\n",
      "794 [G loss: 0.0007741996087133884]\n",
      "795 [G loss: 0.0007804650813341141]\n",
      "796 [G loss: 0.0007857894524931908]\n",
      "797 [G loss: 0.0007969943108037114]\n",
      "798 [G loss: 0.0008036841754801571]\n",
      "799 [G loss: 0.0008177231065928936]\n",
      "800 [G loss: 0.0008189533837139606]\n",
      "801 [G loss: 0.0008246659999713302]\n",
      "802 [G loss: 0.0008126122993417084]\n",
      "803 [G loss: 0.0008017096552066505]\n",
      "804 [G loss: 0.0007858730969019234]\n",
      "805 [G loss: 0.0007758436258882284]\n",
      "806 [G loss: 0.0007735842373222113]\n",
      "807 [G loss: 0.0007753053214401007]\n",
      "808 [G loss: 0.0007806153735145926]\n",
      "809 [G loss: 0.0007807374349795282]\n",
      "810 [G loss: 0.0007799601880833507]\n",
      "811 [G loss: 0.0007737652049399912]\n",
      "812 [G loss: 0.0007686925819143653]\n",
      "813 [G loss: 0.0007647277670912445]\n",
      "814 [G loss: 0.000763339689001441]\n",
      "815 [G loss: 0.0007642226992174983]\n",
      "816 [G loss: 0.0007647171732969582]\n",
      "817 [G loss: 0.000765881035476923]\n",
      "818 [G loss: 0.0007647506427019835]\n",
      "819 [G loss: 0.0007641311385668814]\n",
      "820 [G loss: 0.000761692295782268]\n",
      "821 [G loss: 0.0007599772652611136]\n",
      "822 [G loss: 0.0007578171789646149]\n",
      "823 [G loss: 0.0007566110580228269]\n",
      "824 [G loss: 0.0007560075027868152]\n",
      "825 [G loss: 0.0007557016215287149]\n",
      "826 [G loss: 0.0007558753713965416]\n",
      "827 [G loss: 0.0007556824712082744]\n",
      "828 [G loss: 0.0007563252584077418]\n",
      "829 [G loss: 0.0007566219428554177]\n",
      "830 [G loss: 0.0007582874968647957]\n",
      "831 [G loss: 0.0007591346511617303]\n",
      "832 [G loss: 0.0007613742491230369]\n",
      "833 [G loss: 0.0007620067335665226]\n",
      "834 [G loss: 0.000764392432756722]\n",
      "835 [G loss: 0.000764810130931437]\n",
      "836 [G loss: 0.0007672801730223]\n",
      "837 [G loss: 0.0007668989710509777]\n",
      "838 [G loss: 0.0007683720905333757]\n",
      "839 [G loss: 0.0007666033925488591]\n",
      "840 [G loss: 0.0007665423909202218]\n",
      "841 [G loss: 0.0007639419054612517]\n",
      "842 [G loss: 0.0007636958034709096]\n",
      "843 [G loss: 0.0007629318861290812]\n",
      "844 [G loss: 0.0007649930194020271]\n",
      "845 [G loss: 0.0007671086932532489]\n",
      "846 [G loss: 0.000771074672229588]\n",
      "847 [G loss: 0.0007745411712676287]\n",
      "848 [G loss: 0.0007788412040099502]\n",
      "849 [G loss: 0.0007822058396413922]\n",
      "850 [G loss: 0.0007852846756577492]\n",
      "851 [G loss: 0.0007854932337068021]\n",
      "852 [G loss: 0.0007837311713956296]\n",
      "853 [G loss: 0.0007778573781251907]\n",
      "854 [G loss: 0.0007705920143052936]\n",
      "855 [G loss: 0.0007622743723914027]\n",
      "856 [G loss: 0.0007568097207695246]\n",
      "857 [G loss: 0.0007534871692769229]\n",
      "858 [G loss: 0.0007531704613938928]\n",
      "859 [G loss: 0.0007533024763688445]\n",
      "860 [G loss: 0.0007544031832367182]\n",
      "861 [G loss: 0.0007542235543951392]\n",
      "862 [G loss: 0.0007540045189671218]\n",
      "863 [G loss: 0.0007519125356338918]\n",
      "864 [G loss: 0.0007496951729990542]\n",
      "865 [G loss: 0.0007470111013390124]\n",
      "866 [G loss: 0.0007452144054695964]\n",
      "867 [G loss: 0.0007441184716299176]\n",
      "868 [G loss: 0.0007434589206241071]\n",
      "869 [G loss: 0.0007434295257553458]\n",
      "870 [G loss: 0.0007432198617607355]\n",
      "871 [G loss: 0.0007437432650476694]\n",
      "872 [G loss: 0.000743940647225827]\n",
      "873 [G loss: 0.0007455233717337251]\n",
      "874 [G loss: 0.0007465998642146587]\n",
      "875 [G loss: 0.0007504455279558897]\n",
      "876 [G loss: 0.0007539240759797394]\n",
      "877 [G loss: 0.0007622940465807915]\n",
      "878 [G loss: 0.0007687347242608666]\n",
      "879 [G loss: 0.0007821242325007915]\n",
      "880 [G loss: 0.0007877688040025532]\n",
      "881 [G loss: 0.0008005268173292279]\n",
      "882 [G loss: 0.00079701142385602]\n",
      "883 [G loss: 0.0007968227146193385]\n",
      "884 [G loss: 0.000781863636802882]\n",
      "885 [G loss: 0.0007701867143623531]\n",
      "886 [G loss: 0.000759637332521379]\n",
      "887 [G loss: 0.0007542910170741379]\n",
      "888 [G loss: 0.0007550250156782568]\n",
      "889 [G loss: 0.0007549754809588194]\n",
      "890 [G loss: 0.0007562934188172221]\n",
      "891 [G loss: 0.0007530134171247482]\n",
      "892 [G loss: 0.0007504172390326858]\n",
      "893 [G loss: 0.000746391830034554]\n",
      "894 [G loss: 0.0007439472246915102]\n",
      "895 [G loss: 0.0007427615346387029]\n",
      "896 [G loss: 0.0007415218860842288]\n",
      "897 [G loss: 0.0007411176338791847]\n",
      "898 [G loss: 0.0007393082487396896]\n",
      "899 [G loss: 0.0007384555647149682]\n",
      "900 [G loss: 0.0007369688246399164]\n",
      "901 [G loss: 0.0007365701021626592]\n",
      "902 [G loss: 0.0007358501898124814]\n",
      "903 [G loss: 0.0007352932589128613]\n",
      "904 [G loss: 0.0007344840560108423]\n",
      "905 [G loss: 0.0007333647226914763]\n",
      "906 [G loss: 0.0007325019687414169]\n",
      "907 [G loss: 0.0007313338574022055]\n",
      "908 [G loss: 0.0007306113839149475]\n",
      "909 [G loss: 0.0007295948453247547]\n",
      "910 [G loss: 0.0007291542715393007]\n",
      "911 [G loss: 0.0007287687039934099]\n",
      "912 [G loss: 0.0007290744106285274]\n",
      "913 [G loss: 0.0007293390808627009]\n",
      "914 [G loss: 0.0007303176098503172]\n",
      "915 [G loss: 0.0007311701192520559]\n",
      "916 [G loss: 0.0007334842812269926]\n",
      "917 [G loss: 0.0007358815055340528]\n",
      "918 [G loss: 0.0007411461556330323]\n",
      "919 [G loss: 0.0007455716840922832]\n",
      "920 [G loss: 0.0007541779195889831]\n",
      "921 [G loss: 0.0007591424509882927]\n",
      "922 [G loss: 0.0007687024772167206]\n",
      "923 [G loss: 0.0007696208776906133]\n",
      "924 [G loss: 0.0007729733479209244]\n",
      "925 [G loss: 0.000764479162171483]\n",
      "926 [G loss: 0.0007564442930743098]\n",
      "927 [G loss: 0.0007442060741595924]\n",
      "928 [G loss: 0.0007362401811406016]\n",
      "929 [G loss: 0.00073341274401173]\n",
      "930 [G loss: 0.000734654488041997]\n",
      "931 [G loss: 0.0007391368853859603]\n",
      "932 [G loss: 0.0007409615209326148]\n",
      "933 [G loss: 0.0007425799849443138]\n",
      "934 [G loss: 0.0007390014361590147]\n",
      "935 [G loss: 0.0007358859293162823]\n",
      "936 [G loss: 0.0007309286156669259]\n",
      "937 [G loss: 0.0007281748112291098]\n",
      "938 [G loss: 0.0007262596627697349]\n",
      "939 [G loss: 0.0007256991229951382]\n",
      "940 [G loss: 0.0007259070407599211]\n",
      "941 [G loss: 0.0007258073310367763]\n",
      "942 [G loss: 0.000726390047930181]\n",
      "943 [G loss: 0.0007260603015311062]\n",
      "944 [G loss: 0.0007267041364684701]\n",
      "945 [G loss: 0.0007260804995894432]\n",
      "946 [G loss: 0.0007264306186698377]\n",
      "947 [G loss: 0.0007253482472151518]\n",
      "948 [G loss: 0.0007250473136082292]\n",
      "949 [G loss: 0.0007236909586936235]\n",
      "950 [G loss: 0.0007231462514027953]\n",
      "951 [G loss: 0.0007221882697194815]\n",
      "952 [G loss: 0.00072204734897241]\n",
      "953 [G loss: 0.0007216061931103468]\n",
      "954 [G loss: 0.0007218112586997449]\n",
      "955 [G loss: 0.0007218081154860556]\n",
      "956 [G loss: 0.0007224884466268122]\n",
      "957 [G loss: 0.0007230789633467793]\n",
      "958 [G loss: 0.0007244289154186845]\n",
      "959 [G loss: 0.0007255768869072199]\n",
      "960 [G loss: 0.000728014565538615]\n",
      "961 [G loss: 0.0007304245373234153]\n",
      "962 [G loss: 0.0007357153808698058]\n",
      "963 [G loss: 0.0007407172815874219]\n",
      "964 [G loss: 0.000750737963244319]\n",
      "965 [G loss: 0.0007580128731206059]\n",
      "966 [G loss: 0.0007725891773588955]\n",
      "967 [G loss: 0.0007785271154716611]\n",
      "968 [G loss: 0.0007894954178482294]\n",
      "969 [G loss: 0.0007830075919628143]\n",
      "970 [G loss: 0.0007753801764920354]\n",
      "971 [G loss: 0.0007583907572552562]\n",
      "972 [G loss: 0.0007445379160344601]\n",
      "973 [G loss: 0.0007397072040475905]\n",
      "974 [G loss: 0.0007385440403595567]\n",
      "975 [G loss: 0.0007433674763888121]\n",
      "976 [G loss: 0.0007413320709019899]\n",
      "977 [G loss: 0.0007385421777144074]\n",
      "978 [G loss: 0.0007302277954295278]\n",
      "979 [G loss: 0.0007245248416438699]\n",
      "980 [G loss: 0.0007223488646559417]\n",
      "981 [G loss: 0.0007221162086352706]\n",
      "982 [G loss: 0.0007237963145598769]\n",
      "983 [G loss: 0.0007228719186969101]\n",
      "984 [G loss: 0.0007219343679025769]\n",
      "985 [G loss: 0.0007185477879829705]\n",
      "986 [G loss: 0.0007157661020755768]\n",
      "987 [G loss: 0.0007135770283639431]\n",
      "988 [G loss: 0.0007125246338546276]\n",
      "989 [G loss: 0.0007129149162210524]\n",
      "990 [G loss: 0.0007130574667826295]\n",
      "991 [G loss: 0.000713551533408463]\n",
      "992 [G loss: 0.0007125834817998111]\n",
      "993 [G loss: 0.0007116985507309437]\n",
      "994 [G loss: 0.00070998101728037]\n",
      "995 [G loss: 0.000708883919287473]\n",
      "996 [G loss: 0.0007078465423546731]\n",
      "997 [G loss: 0.0007072736625559628]\n",
      "998 [G loss: 0.0007067742990329862]\n",
      "999 [G loss: 0.0007063145749270916]\n"
     ]
    }
   ],
   "source": [
    "def train_wave_gan(generator, data, latent_dim, epochs=1000, batch_size=32):\n",
    "    # half_batch = batch_size // 2\n",
    "    for epoch in range(epochs):\n",
    "        for input_image, audio in data.take(len(images)):\n",
    "\n",
    "#PREVIOUS CODE INCLUDING THE USE OF THE DISCRIMINATOR\n",
    "#         # if (step) % 1000 == 0:\n",
    "            # num += 1\n",
    "#         # discriminator.trainable=True\n",
    "\n",
    "#         # idx = np.random.randint(0, data.shape[0], half_batch)\n",
    "#         # real_samples = data[idx]\n",
    "#         # print(real_samples.shape)\n",
    "#         # real_labels = np.ones((half_batch, 1))\n",
    "\n",
    "#         # noise = np.random.normal(0, 1, (half_batch, latent_dim))\n",
    "#         # fake_samples = generator.predict(noise)\n",
    "#         # fake_labels = np.zeros((half_batch, 1))\n",
    "\n",
    "#         # d_loss_real = discriminator.train_on_batch(real_samples, real_labels)\n",
    "#         # d_loss_fake = discriminator.train_on_batch(fake_samples, fake_labels)\n",
    "\n",
    "#         # d_loss = np.add(d_loss_real, d_loss_fake) * 0.5\n",
    "\n",
    "#         # discriminator.trainable = False\n",
    "\n",
    "            # noise = np.random.normal(0, 1, (batch_size, latent_dim))\n",
    "            # for i, o in zip(audio, input_image):\n",
    "            #     num += 1\n",
    "            #     sf.write(f'generated_audio{num}.wav', i, 16000)\n",
    "            #     generate_images(o, num)\n",
    "        \n",
    "            \n",
    "            # sf.write(f'generated_audio{num}.wav', generated_audio, 16000)\n",
    "#         # valid_y = np.ones((batch_size, 1))\n",
    "        \n",
    "        #TRAINED WITHOUT THE DISCRIMINATOR\n",
    "            gan_loss = generator.train_on_batch(input_image, audio)\n",
    "\n",
    "        print(f\"{epoch} [G loss: {gan_loss}]\")\n",
    "\n",
    "train_wave_gan(generator, data, latent_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c95d1ae1-8566-48be-9e66-1463f44ff493",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_images(img, num):\n",
    "  # img = model(test_input, training=True)\n",
    "\n",
    "  plt.figure(figsize=(5, 5))\n",
    "\n",
    "  # display_list = [test_input[0], tar[0], img[0]]\n",
    "  title = str(num)\n",
    "\n",
    "  for i in range(1):\n",
    "    plt.subplot(1, 1, i+1)\n",
    "    plt.title(title)\n",
    "    plt.imshow(img * 0.5 + 0.5)\n",
    "    plt.axis('off')\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "915fc7e0-5511-42d2-84ef-401c0bd3fccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generator.fit(data, epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d1996520-68f8-4759-9b8a-a67cf8e77d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gene = tf.keras.models.load_model('gn_da_audio.h5',\n",
    "#                                   custom_objects={\n",
    "#                                       \"custom_loss\": custom_loss,\n",
    "#                                   }\n",
    "#                                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "780aeb78-2ec5-488e-aa8d-bf54b7944acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(image_file):\n",
    "    # Load the image from the file path\n",
    "\n",
    "    file = image_file\n",
    "    image = tf.io.read_file(file)\n",
    "    # Decode the image (e.g., JPEG or PNG)\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    # Resize the image to your desired dimensions\n",
    "    image = tf.image.resize(image, [128, 128])\n",
    "    # Normalize pixel values (optional)\n",
    "    image = (image / 127.5) - 1\n",
    "        \n",
    "\n",
    "    return image\n",
    "\n",
    "image = load_image(\"C://Users//anang//OneDrive//Desktop//Image to Audio//sound images//Tiger/1animal-4004844_640.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee16ff6-c7ea-4f4a-aab3-b51964544d60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step\n",
      "[[[ 0.01365701]\n",
      "  [ 0.01492188]\n",
      "  [ 0.01595006]\n",
      "  ...\n",
      "  [ 0.00161182]\n",
      "  [-0.00713945]\n",
      "  [ 0.00765297]]]\n"
     ]
    }
   ],
   "source": [
    "def generate_audio(generator, latent_dim, length, image):\n",
    "    # noise = np.random.normal(0, 1, (1, latent_dim))\n",
    "    image = tf.expand_dims(image, axis=0)\n",
    "    generated_audio = generator.predict(image)\n",
    "    print(generated_audio)\n",
    "    return generated_audio.flatten()\n",
    "\n",
    "generated_audio = generate_audio(generator, latent_dim, output_shape[0], image)\n",
    "\n",
    "# Save the generated audio using soundfile\n",
    "import soundfile as sf\n",
    "sf.write('generated_audio.wav', generated_audio, 16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "448173f2-1ea9-4873-9182-8b18af48ee25",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anang\\AppData\\Local\\Temp\\ipykernel_27108\\2749786185.py:1: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  tf.keras.models.save_model(generator, 'new_gen_gen_audio.h5')\n"
     ]
    }
   ],
   "source": [
    "tf.keras.models.save_model(generator, 'new_gen_gen_audio.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "821fa774-f27e-4756-9897-f37574c919df",
   "metadata": {},
   "outputs": [],
   "source": [
    "gene = tf.keras.models.load_model('new_gen_gen_audio.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
